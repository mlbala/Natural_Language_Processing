{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/bk/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to understand, interpret, and generate human language. \n",
    "It combines computational linguistics with machine learning techniques to analyze text and speech data! powering applications like chatbots, translation services, and sentiment analysis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to understand, interpret, and generate human language. \n",
      "It combines computational linguistics with machine learning techniques to analyze text and speech data! powering applications like chatbots, translation services, and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Sentence --> Paragraph\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "document = sent_tokenize(corpus)\n",
    "# sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to understand, interpret, and generate human language.\n",
      "It combines computational linguistics with machine learning techniques to analyze text and speech data!\n",
      "powering applications like chatbots, translation services, and sentiment analysis.\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Paragraph --> words\n",
    "## Sentence --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'enabling',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'combines',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'data',\n",
       " '!',\n",
       " 'powering',\n",
       " 'applications',\n",
       " 'like',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'translation',\n",
       " 'services',\n",
       " ',',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'AI', 'that', 'focuses', 'on', 'enabling', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.']\n",
      "['It', 'combines', 'computational', 'linguistics', 'with', 'machine', 'learning', 'techniques', 'to', 'analyze', 'text', 'and', 'speech', 'data', '!']\n",
      "['powering', 'applications', 'like', 'chatbots', ',', 'translation', 'services', ',', 'and', 'sentiment', 'analysis', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'enabling',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'It',\n",
       " 'combines',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'data',\n",
       " '!',\n",
       " 'powering',\n",
       " 'applications',\n",
       " 'like',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'translation',\n",
       " 'services',\n",
       " ',',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'enabling',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " ',',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'and',\n",
       " 'generate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'It',\n",
       " 'combines',\n",
       " 'computational',\n",
       " 'linguistics',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'techniques',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'data',\n",
       " '!',\n",
       " 'powering',\n",
       " 'applications',\n",
       " 'like',\n",
       " 'chatbots',\n",
       " ',',\n",
       " 'translation',\n",
       " 'services',\n",
       " ',',\n",
       " 'and',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
